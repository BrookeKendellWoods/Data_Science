{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf81ab66",
   "metadata": {},
   "source": [
    "this dataset is called MNIST and refers to datawritten digit recognition \n",
    "\n",
    "this dataset contains 70,000 images(28x28 pixels) of handwritten digits(1 image per digit)\n",
    "the goal is to write an algorithim that detects which digits are written. Since there are only 10 digits (0,1,2,3,4,5,6,7,8,9) this is a classification problem with 10 classes\n",
    "\n",
    "Goal is to build a neural network with 2 hidden layers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb5b18c",
   "metadata": {},
   "source": [
    "# import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f7c96044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae11379",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e8c3ba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset, mnist_info = tfds.load(name = 'mnist', with_info=True, as_supervised=True) #as_supervised = True loads into two tupel structure : input and target, with_info provides tuple with info\n",
    "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']\n",
    "#by default has training and testing but no validation datasets, gives us opportunity to practice splitting datasets on our own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c25a22a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples #can either count number of training samples or use mnist_info variable, get a number = to number of training samples /n\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64) #to solve issue of not knowing whether at integer, will cast to integer to prevent any further issues\n",
    "\n",
    "num_test_samples = mnist_info.splits['test'].num_examples\n",
    "num_test_samples =tf.cast(num_test_samples, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "78099500",
   "metadata": {},
   "outputs": [],
   "source": [
    "#would like to scale data in some way to make results more numerically stable (prefer inputs between 0 - 1 )\n",
    "\n",
    "\n",
    "\n",
    "def scale(image, label): #function to scale inputs with parameters image and label \n",
    "    image = tf.cast(image, tf.float32)  # make sure all values are floats \n",
    "    image /= 255. # contains values 0 - 255 so if divide every element by 255, every element will between 0 and 1, the dot at end signfies we want result to be a float \n",
    "    return image, label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "af94507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train_and_validation = mnist_train.map(scale)#tensorflow map method allows us to apply custom transformation to a given dataset\n",
    "\n",
    "test_data = mnist_test.map(scale) #can only take input and label and return input and label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a3ea8436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since batching, better shuffle the data. Use minibatch gradient discent to shuffl\n",
    "BUFFER_SIZE = 10000 #buffersize parameter used in cases with huge datasets, can't shuffle at once because too big to fit in memory would want to shuffle 10,000 at a time. if buffersize=1 no shuffling will actually happen and if buffersize is = or bigger than the total number of samples, shuffling will take place at once and will take place uniformly \n",
    "\n",
    "shuffled_train_and_validation = scaled_train_and_validation.shuffle(BUFFER_SIZE)#there is a shuffle method readily available \n",
    "\n",
    "validation_data = shuffled_train_and_validation.take(num_validation_samples) #use method take to extract mini samples \n",
    "\n",
    "train_data = shuffled_train_validation.skip(num_validation_samples) #extract all elements but the x validation samples\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "\n",
    "validation_data = validation_data.batch(num_validation_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
