{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7467d606",
   "metadata": {},
   "source": [
    "# import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e900f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5387583",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "69c92154",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_csv_data = np.loadtxt(\"Audiobooks_data.csv\", delimiter = ',') #inputs are all variable in csv except first and last col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159337d1",
   "metadata": {},
   "source": [
    "# extract inputs and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5721fe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "unscaled_inputs_all = raw_csv_data[:,1:-1] #takes all columns excluding the ID and target ( 1st and last col )\n",
    "targets_all = raw_csv_data[:,-1] #last column (target column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15a6b06",
   "metadata": {},
   "source": [
    "# balance the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d0568774",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_one_targets = int(np.sum(targets_all)) ###count number of targets that are ones since we know less than 0 & keep as many zeros as ones\n",
    "num_zero_targets = 0 ###counter for targets equal to 0 \n",
    "indices_to_remove = [] ###variable that declares indices to remove\n",
    "\n",
    "for i in range(targets_all.shape[0]): #shape on 0 axis is basically length of the vector so shows the number of all targets \n",
    "    if targets_all[i] == 0: # in loop increase counter by 1 if the target at position i is 0 \n",
    "        num_zero_targets += 1\n",
    "        if num_zero_targets > num_one_targets: #in same if add another if which adds an index for the variable indices to remove if the zeros counter is over the number of ones \n",
    "            indices_to_remove.append(i) #after counter for 0 matches # of ones, all indexes will be removed, indices_to_remove will contain all indexes we dont need \n",
    "            \n",
    "unscaled_inputs_equal_priors = np.delete(unscaled_inputs_all, indices_to_remove, axis=0) #deleting balances the dataset \n",
    "\n",
    "targets_equal_priors = np.delete(targets_all, indices_to_remove, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435c9af9",
   "metadata": {},
   "source": [
    "# standardize the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "939973ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_inputs = preprocessing.scale(unscaled_inputs_equal_priors) #the scale method standardizes the dataset along each variable ( so basically all inputs will be standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630fb4ac",
   "metadata": {},
   "source": [
    "# shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f1dc8035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep same information in a different order.Possible that dataset collected in order of date so batch to make random\n",
    "shuffled_indices = np.arange(scaled_inputs.shape[0]) #take indexes from axis 0 of scaled input shape and place them in a variable \n",
    "np.random.shuffle(shuffled_indices) #use np.random.shuffle method to shuffle them\n",
    "\n",
    "shuffled_inputs = scaled_inputs[shuffled_indices] #equal to s\n",
    "shuffled_targets = targets_equal_priors[shuffled_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4bc439",
   "metadata": {},
   "source": [
    "# split data into train, validation, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "289e8944",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_count = shuffled_inputs.shape[0]\n",
    "\n",
    "train_samples_count = int(0.8* samples_count)\n",
    "validation_samples_count = int(0.1 * samples_count)\n",
    "test_samples_count = samples_count - train_samples_count - validation_samples_count\n",
    "\n",
    "int(samples_count)\n",
    "\n",
    "train_inputs = shuffled_inputs[:train_samples_count]\n",
    "train_targets = shuffled_targets[:train_samples_count]\n",
    "\n",
    "validation_inputs = shuffled_inputs[train_samples_count:train_samples_count + validation_samples_count]\n",
    "validation_targets = shuffled_inputs[train_samples_count:train_samples_count + validation_samples_count]\n",
    "\n",
    "\n",
    "test_inputs = shuffled_inputs[train_samples_count+validation_samples_count:]\n",
    "test_targets = shuffled_inputs[train_samples_count+validation_samples_count:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "521d2069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1763.0 3579 0.49259569712210116\n",
      "-80.98237910092038 447 -0.18116863333539235\n",
      "130.82591270747614 448 0.2920221265791878\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(train_targets), train_samples_count, np.sum(train_targets) / train_samples_count)\n",
    "print(np.sum(validation_targets), validation_samples_count, np.sum(validation_targets) / validation_samples_count)\n",
    "print(np.sum(test_targets), test_samples_count, np.sum(test_targets) / test_samples_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae60116",
   "metadata": {},
   "source": [
    "# save 3 datasets in *.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2ea542c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"Audiobooks_train_data\", inputs=train_inputs, targets=train_targets)\n",
    "np.savez(\"Audiobooks_validation_data\", inputs=validation_inputs, targets=validation_targets)\n",
    "np.savez(\"Audiobooks_test_data\", inputs=test_inputs, targets=test_targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
